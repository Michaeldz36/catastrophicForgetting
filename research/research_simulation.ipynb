{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# starting imports\n",
    "import pandas as pd\n",
    "from utils.utils import Setup\n",
    "from collections import Counter\n",
    "from research.main import main, simulate, plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate setup and teachers\n",
    "setup = Setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters, can be modified\n",
    "N1 = N2 = setup.N * 1  # for now N=N1=N2\n",
    "batch_size = setup.P * 1\n",
    "P1 = setup.P * 1\n",
    "P2 = setup.P * 1\n",
    "learning_rate = 1e-2\n",
    "epochs1 = 500\n",
    "epochs2 = 500\n",
    "sgm_e = setup.sgm_e\n",
    "sgm_w1 = setup.sgm_w * 1\n",
    "sgm_w2 = setup.sgm_w * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realisation 0/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0098\n",
      "val Loss: 0.0926\n",
      "cross_gen Loss: 0.3679\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0039\n",
      "val Loss: 0.0942\n",
      "cross_gen Loss: 0.3836\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0973\n",
      "cross_gen Loss: 0.3957\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0993\n",
      "cross_gen Loss: 0.4044\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.1001\n",
      "cross_gen Loss: 0.4108\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.1001\n",
      "cross_gen Loss: 0.4157\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0996\n",
      "cross_gen Loss: 0.4195\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0988\n",
      "cross_gen Loss: 0.4224\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0978\n",
      "cross_gen Loss: 0.4249\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0969\n",
      "cross_gen Loss: 0.4268\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0140\n",
      "val Loss: 0.2678\n",
      "cross_gen Loss: 0.1453\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.2655\n",
      "cross_gen Loss: 0.1838\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.2649\n",
      "cross_gen Loss: 0.1932\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.2640\n",
      "cross_gen Loss: 0.1965\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.2628\n",
      "cross_gen Loss: 0.1982\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.2617\n",
      "cross_gen Loss: 0.1992\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.2608\n",
      "cross_gen Loss: 0.2000\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2600\n",
      "cross_gen Loss: 0.2005\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2593\n",
      "cross_gen Loss: 0.2010\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2588\n",
      "cross_gen Loss: 0.2014\n",
      "\n",
      "\n",
      "Realisation 1/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0093\n",
      "val Loss: 0.1319\n",
      "cross_gen Loss: 0.2866\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.1301\n",
      "cross_gen Loss: 0.2790\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.1274\n",
      "cross_gen Loss: 0.2761\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.1249\n",
      "cross_gen Loss: 0.2743\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.1228\n",
      "cross_gen Loss: 0.2730\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.1210\n",
      "cross_gen Loss: 0.2719\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1195\n",
      "cross_gen Loss: 0.2710\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1183\n",
      "cross_gen Loss: 0.2702\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1173\n",
      "cross_gen Loss: 0.2695\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1164\n",
      "cross_gen Loss: 0.2689\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0174\n",
      "val Loss: 0.8141\n",
      "cross_gen Loss: 0.0650\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0078\n",
      "val Loss: 0.7275\n",
      "cross_gen Loss: 0.0899\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0046\n",
      "val Loss: 0.6821\n",
      "cross_gen Loss: 0.1060\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.6538\n",
      "cross_gen Loss: 0.1176\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0023\n",
      "val Loss: 0.6344\n",
      "cross_gen Loss: 0.1263\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.6199\n",
      "cross_gen Loss: 0.1329\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.6088\n",
      "cross_gen Loss: 0.1382\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.5999\n",
      "cross_gen Loss: 0.1425\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.5927\n",
      "cross_gen Loss: 0.1461\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.5867\n",
      "cross_gen Loss: 0.1491\n",
      "\n",
      "\n",
      "Realisation 2/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0190\n",
      "val Loss: 0.1628\n",
      "cross_gen Loss: 0.3987\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0062\n",
      "val Loss: 0.0923\n",
      "cross_gen Loss: 0.3816\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0024\n",
      "val Loss: 0.0692\n",
      "cross_gen Loss: 0.3735\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0594\n",
      "cross_gen Loss: 0.3694\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0547\n",
      "cross_gen Loss: 0.3672\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0522\n",
      "cross_gen Loss: 0.3661\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0508\n",
      "cross_gen Loss: 0.3656\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0500\n",
      "cross_gen Loss: 0.3656\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0495\n",
      "cross_gen Loss: 0.3657\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0492\n",
      "cross_gen Loss: 0.3659\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0215\n",
      "val Loss: 0.3598\n",
      "cross_gen Loss: 0.0956\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0053\n",
      "val Loss: 0.3088\n",
      "cross_gen Loss: 0.1402\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.2918\n",
      "cross_gen Loss: 0.1626\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.2826\n",
      "cross_gen Loss: 0.1754\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.2764\n",
      "cross_gen Loss: 0.1830\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.2719\n",
      "cross_gen Loss: 0.1876\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2683\n",
      "cross_gen Loss: 0.1905\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2655\n",
      "cross_gen Loss: 0.1924\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.2632\n",
      "cross_gen Loss: 0.1936\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.2614\n",
      "cross_gen Loss: 0.1944\n",
      "\n",
      "\n",
      "Realisation 3/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0075\n",
      "val Loss: 0.0945\n",
      "cross_gen Loss: 0.2201\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0832\n",
      "cross_gen Loss: 0.2325\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0811\n",
      "cross_gen Loss: 0.2397\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0820\n",
      "cross_gen Loss: 0.2446\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0840\n",
      "cross_gen Loss: 0.2483\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0861\n",
      "cross_gen Loss: 0.2513\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0882\n",
      "cross_gen Loss: 0.2538\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0902\n",
      "cross_gen Loss: 0.2559\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0921\n",
      "cross_gen Loss: 0.2577\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0938\n",
      "cross_gen Loss: 0.2593\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0250\n",
      "val Loss: 0.3337\n",
      "cross_gen Loss: 0.0935\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0063\n",
      "val Loss: 0.4064\n",
      "cross_gen Loss: 0.1619\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.4312\n",
      "cross_gen Loss: 0.1952\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.4362\n",
      "cross_gen Loss: 0.2122\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.4348\n",
      "cross_gen Loss: 0.2220\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.4318\n",
      "cross_gen Loss: 0.2283\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.4289\n",
      "cross_gen Loss: 0.2327\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.4263\n",
      "cross_gen Loss: 0.2359\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.4242\n",
      "cross_gen Loss: 0.2383\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.4226\n",
      "cross_gen Loss: 0.2401\n",
      "\n",
      "\n",
      "Realisation 4/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0106\n",
      "val Loss: 0.0908\n",
      "cross_gen Loss: 0.2558\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.1100\n",
      "cross_gen Loss: 0.2707\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.1218\n",
      "cross_gen Loss: 0.2762\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.1282\n",
      "cross_gen Loss: 0.2783\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1319\n",
      "cross_gen Loss: 0.2792\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1341\n",
      "cross_gen Loss: 0.2795\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1355\n",
      "cross_gen Loss: 0.2795\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1364\n",
      "cross_gen Loss: 0.2795\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1371\n",
      "cross_gen Loss: 0.2795\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1375\n",
      "cross_gen Loss: 0.2794\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0095\n",
      "val Loss: 0.5034\n",
      "cross_gen Loss: 0.0915\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.4399\n",
      "cross_gen Loss: 0.1160\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.4211\n",
      "cross_gen Loss: 0.1242\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.4148\n",
      "cross_gen Loss: 0.1287\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.4126\n",
      "cross_gen Loss: 0.1319\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.4119\n",
      "cross_gen Loss: 0.1344\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.4117\n",
      "cross_gen Loss: 0.1366\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.4118\n",
      "cross_gen Loss: 0.1384\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.4119\n",
      "cross_gen Loss: 0.1400\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.4121\n",
      "cross_gen Loss: 0.1414\n",
      "\n",
      "\n",
      "Realisation 5/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0065\n",
      "val Loss: 0.1072\n",
      "cross_gen Loss: 0.2670\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0968\n",
      "cross_gen Loss: 0.2863\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0946\n",
      "cross_gen Loss: 0.2969\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0938\n",
      "cross_gen Loss: 0.3036\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0933\n",
      "cross_gen Loss: 0.3082\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0929\n",
      "cross_gen Loss: 0.3115\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0926\n",
      "cross_gen Loss: 0.3141\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0923\n",
      "cross_gen Loss: 0.3161\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0921\n",
      "cross_gen Loss: 0.3177\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0919\n",
      "cross_gen Loss: 0.3191\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0280\n",
      "val Loss: 0.3462\n",
      "cross_gen Loss: 0.1008\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0103\n",
      "val Loss: 0.2905\n",
      "cross_gen Loss: 0.1659\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0053\n",
      "val Loss: 0.2734\n",
      "cross_gen Loss: 0.2049\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0032\n",
      "val Loss: 0.2685\n",
      "cross_gen Loss: 0.2313\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.2684\n",
      "cross_gen Loss: 0.2503\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.2704\n",
      "cross_gen Loss: 0.2645\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.2734\n",
      "cross_gen Loss: 0.2754\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.2769\n",
      "cross_gen Loss: 0.2842\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.2804\n",
      "cross_gen Loss: 0.2915\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.2840\n",
      "cross_gen Loss: 0.2977\n",
      "\n",
      "\n",
      "Realisation 6/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0049\n",
      "val Loss: 0.0975\n",
      "cross_gen Loss: 0.5310\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0978\n",
      "cross_gen Loss: 0.5534\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0970\n",
      "cross_gen Loss: 0.5616\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0962\n",
      "cross_gen Loss: 0.5655\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0957\n",
      "cross_gen Loss: 0.5678\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0954\n",
      "cross_gen Loss: 0.5694\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0952\n",
      "cross_gen Loss: 0.5704\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0950\n",
      "cross_gen Loss: 0.5712\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0950\n",
      "cross_gen Loss: 0.5718\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0949\n",
      "cross_gen Loss: 0.5723\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "val Loss: 0.2550\n",
      "cross_gen Loss: 0.2151\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0113\n",
      "val Loss: 0.2394\n",
      "cross_gen Loss: 0.2849\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0054\n",
      "val Loss: 0.2382\n",
      "cross_gen Loss: 0.3121\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0027\n",
      "val Loss: 0.2365\n",
      "cross_gen Loss: 0.3283\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.2348\n",
      "cross_gen Loss: 0.3395\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.2335\n",
      "cross_gen Loss: 0.3476\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.2326\n",
      "cross_gen Loss: 0.3537\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.2321\n",
      "cross_gen Loss: 0.3583\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.2318\n",
      "cross_gen Loss: 0.3618\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2317\n",
      "cross_gen Loss: 0.3646\n",
      "\n",
      "\n",
      "Realisation 7/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0046\n",
      "val Loss: 0.1024\n",
      "cross_gen Loss: 0.5144\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0834\n",
      "cross_gen Loss: 0.5311\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0755\n",
      "cross_gen Loss: 0.5390\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0709\n",
      "cross_gen Loss: 0.5429\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0679\n",
      "cross_gen Loss: 0.5452\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0658\n",
      "cross_gen Loss: 0.5466\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0644\n",
      "cross_gen Loss: 0.5476\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0633\n",
      "cross_gen Loss: 0.5484\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0626\n",
      "cross_gen Loss: 0.5491\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0621\n",
      "cross_gen Loss: 0.5497\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0251\n",
      "val Loss: 0.3309\n",
      "cross_gen Loss: 0.1366\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0068\n",
      "val Loss: 0.2726\n",
      "cross_gen Loss: 0.1615\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.2476\n",
      "cross_gen Loss: 0.1695\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.2345\n",
      "cross_gen Loss: 0.1732\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.2269\n",
      "cross_gen Loss: 0.1753\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.2223\n",
      "cross_gen Loss: 0.1767\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.2191\n",
      "cross_gen Loss: 0.1777\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.2169\n",
      "cross_gen Loss: 0.1784\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2152\n",
      "cross_gen Loss: 0.1789\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2139\n",
      "cross_gen Loss: 0.1793\n",
      "\n",
      "\n",
      "Realisation 8/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0037\n",
      "val Loss: 0.1377\n",
      "cross_gen Loss: 0.3622\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.1439\n",
      "cross_gen Loss: 0.3763\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.1439\n",
      "cross_gen Loss: 0.3806\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1434\n",
      "cross_gen Loss: 0.3820\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1428\n",
      "cross_gen Loss: 0.3824\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1422\n",
      "cross_gen Loss: 0.3824\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1416\n",
      "cross_gen Loss: 0.3824\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1411\n",
      "cross_gen Loss: 0.3822\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1407\n",
      "cross_gen Loss: 0.3821\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1403\n",
      "cross_gen Loss: 0.3819\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0223\n",
      "val Loss: 0.5741\n",
      "cross_gen Loss: 0.1579\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0085\n",
      "val Loss: 0.6002\n",
      "cross_gen Loss: 0.2114\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0053\n",
      "val Loss: 0.6056\n",
      "cross_gen Loss: 0.2303\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.6003\n",
      "cross_gen Loss: 0.2401\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.5920\n",
      "cross_gen Loss: 0.2469\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.5836\n",
      "cross_gen Loss: 0.2524\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.5760\n",
      "cross_gen Loss: 0.2572\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.5696\n",
      "cross_gen Loss: 0.2616\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.5643\n",
      "cross_gen Loss: 0.2655\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.5599\n",
      "cross_gen Loss: 0.2692\n",
      "\n",
      "\n",
      "Realisation 9/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0072\n",
      "val Loss: 0.1139\n",
      "cross_gen Loss: 0.2913\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0982\n",
      "cross_gen Loss: 0.2970\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0994\n",
      "cross_gen Loss: 0.2996\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.1022\n",
      "cross_gen Loss: 0.3006\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1045\n",
      "cross_gen Loss: 0.3010\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1062\n",
      "cross_gen Loss: 0.3011\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1074\n",
      "cross_gen Loss: 0.3011\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1082\n",
      "cross_gen Loss: 0.3012\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1089\n",
      "cross_gen Loss: 0.3012\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1094\n",
      "cross_gen Loss: 0.3013\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0200\n",
      "val Loss: 0.3562\n",
      "cross_gen Loss: 0.1185\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0047\n",
      "val Loss: 0.3279\n",
      "cross_gen Loss: 0.1661\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.3164\n",
      "cross_gen Loss: 0.1848\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.3097\n",
      "cross_gen Loss: 0.1930\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.3056\n",
      "cross_gen Loss: 0.1969\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.3031\n",
      "cross_gen Loss: 0.1988\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.3015\n",
      "cross_gen Loss: 0.1998\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.3005\n",
      "cross_gen Loss: 0.2004\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.2998\n",
      "cross_gen Loss: 0.2008\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.2993\n",
      "cross_gen Loss: 0.2010\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-e3521816a5bf>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[1;31m# averaging over teacher realisations\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[0merrors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mn_runs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 33\u001B[1;33m \u001B[0mplot_history\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\catastrophicForgetting\\research\\main.py\u001B[0m in \u001B[0;36mplot_history\u001B[1;34m(errors)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxlabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Epoch\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mylabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Mean Squared Error\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"(MSE averaged over {} realisations)\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_runs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m     \u001B[1;31m# plt.gca().set_ylim(0, 1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'n_runs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creates a pair of Teachers (T1, T2),\n",
    "each teacher generates:\n",
    " -P examples of N-parameter random vectors X generated from normal distribution\n",
    "with variance sgm_w**2\n",
    " -P examples of linear signal Y created from random vectors.\n",
    " A simple white noise with variance sgm_e**2 is added to the signals.\n",
    "\n",
    "Generated data is splitted with 2:1 ratio for training/validation purposes.\n",
    "\n",
    "Creates Student model, together with SGD optimizer with learning ratio lr and MSE loss function.\n",
    "Prepares training, validation and cross-generalization datasets with scaling of the input vectors.\n",
    "\n",
    "Runs 2 subsequent lessons runned for epochs1 and epochs2 time.\n",
    "Returns dictionary with training, validation and cross generalization errors for full simulation\n",
    "Uses setup organised into \"syllabus\" list, repeats simulation n_runs times and averages over realisation.\n",
    "Finally plots resulting errors.\n",
    "\"\"\"\n",
    "\n",
    "syllabus=[N1, N2,\n",
    "          P1, P2,\n",
    "          sgm_w1, sgm_w2,\n",
    "          sgm_e, learning_rate,\n",
    "          epochs1, epochs2]\n",
    "n_runs=10\n",
    "errors = simulate(syllabus, n_runs)\n",
    "plot_history(errors, n_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}