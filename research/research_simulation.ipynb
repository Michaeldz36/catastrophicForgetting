{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# starting imports\n",
    "import pandas as pd\n",
    "from utils.utils import Setup\n",
    "from collections import Counter\n",
    "from research.main import main, plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# instantiate setup and teachers\n",
    "setup = Setup()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# hyperparameters, can be modified\n",
    "N1 = N2 = setup.N * 1  # for now N=N1=N2\n",
    "batch_size = setup.P * 1\n",
    "P1 = setup.P * 1\n",
    "P2 = setup.P * 1\n",
    "learning_rate = 1e-2\n",
    "epochs1 = 500\n",
    "epochs2 = 500\n",
    "sgm_e = setup.sgm_e\n",
    "sgm_w1 = setup.sgm_w * 1\n",
    "sgm_w2 = setup.sgm_w * 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realisation 0/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0143\n",
      "val Loss: 0.1824\n",
      "cross_gen Loss: 0.2837\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0049\n",
      "val Loss: 0.1564\n",
      "cross_gen Loss: 0.2845\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0023\n",
      "val Loss: 0.1460\n",
      "cross_gen Loss: 0.2861\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.1414\n",
      "cross_gen Loss: 0.2880\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.1394\n",
      "cross_gen Loss: 0.2899\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.1386\n",
      "cross_gen Loss: 0.2915\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.1383\n",
      "cross_gen Loss: 0.2928\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1383\n",
      "cross_gen Loss: 0.2939\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1385\n",
      "cross_gen Loss: 0.2948\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1386\n",
      "cross_gen Loss: 0.2955\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0260\n",
      "val Loss: 0.4508\n",
      "cross_gen Loss: 0.0849\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0092\n",
      "val Loss: 0.3785\n",
      "cross_gen Loss: 0.1203\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0043\n",
      "val Loss: 0.3580\n",
      "cross_gen Loss: 0.1403\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.3489\n",
      "cross_gen Loss: 0.1545\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.3441\n",
      "cross_gen Loss: 0.1649\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.3414\n",
      "cross_gen Loss: 0.1727\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.3398\n",
      "cross_gen Loss: 0.1785\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.3390\n",
      "cross_gen Loss: 0.1828\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.3385\n",
      "cross_gen Loss: 0.1860\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.3384\n",
      "cross_gen Loss: 0.1885\n",
      "\n",
      "\n",
      "Realisation 1/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0047\n",
      "val Loss: 0.1742\n",
      "cross_gen Loss: 0.3580\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.1714\n",
      "cross_gen Loss: 0.3664\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.1706\n",
      "cross_gen Loss: 0.3707\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1704\n",
      "cross_gen Loss: 0.3735\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1705\n",
      "cross_gen Loss: 0.3756\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1705\n",
      "cross_gen Loss: 0.3770\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1705\n",
      "cross_gen Loss: 0.3779\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1705\n",
      "cross_gen Loss: 0.3786\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1704\n",
      "cross_gen Loss: 0.3792\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1704\n",
      "cross_gen Loss: 0.3796\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0180\n",
      "val Loss: 0.5294\n",
      "cross_gen Loss: 0.1030\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0047\n",
      "val Loss: 0.5000\n",
      "cross_gen Loss: 0.1426\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0022\n",
      "val Loss: 0.5029\n",
      "cross_gen Loss: 0.1577\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0012\n",
      "val Loss: 0.5089\n",
      "cross_gen Loss: 0.1646\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.5143\n",
      "cross_gen Loss: 0.1683\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.5190\n",
      "cross_gen Loss: 0.1705\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.5229\n",
      "cross_gen Loss: 0.1720\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.5261\n",
      "cross_gen Loss: 0.1729\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.5288\n",
      "cross_gen Loss: 0.1735\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.5310\n",
      "cross_gen Loss: 0.1740\n",
      "\n",
      "\n",
      "Realisation 2/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0069\n",
      "val Loss: 0.0848\n",
      "cross_gen Loss: 0.2679\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0722\n",
      "cross_gen Loss: 0.2789\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.0648\n",
      "cross_gen Loss: 0.2869\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0604\n",
      "cross_gen Loss: 0.2931\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0576\n",
      "cross_gen Loss: 0.2981\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0558\n",
      "cross_gen Loss: 0.3022\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0545\n",
      "cross_gen Loss: 0.3058\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0536\n",
      "cross_gen Loss: 0.3088\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0530\n",
      "cross_gen Loss: 0.3115\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0526\n",
      "cross_gen Loss: 0.3138\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0236\n",
      "val Loss: 0.7772\n",
      "cross_gen Loss: 0.0656\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0084\n",
      "val Loss: 0.7585\n",
      "cross_gen Loss: 0.0921\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0041\n",
      "val Loss: 0.7427\n",
      "cross_gen Loss: 0.1080\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0023\n",
      "val Loss: 0.7282\n",
      "cross_gen Loss: 0.1186\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.7161\n",
      "cross_gen Loss: 0.1261\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.7064\n",
      "cross_gen Loss: 0.1318\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.6988\n",
      "cross_gen Loss: 0.1361\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.6929\n",
      "cross_gen Loss: 0.1396\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.6883\n",
      "cross_gen Loss: 0.1424\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.6847\n",
      "cross_gen Loss: 0.1447\n",
      "\n",
      "\n",
      "Realisation 3/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0120\n",
      "val Loss: 0.1242\n",
      "cross_gen Loss: 0.2909\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0037\n",
      "val Loss: 0.0985\n",
      "cross_gen Loss: 0.2787\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0874\n",
      "cross_gen Loss: 0.2724\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0816\n",
      "cross_gen Loss: 0.2690\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0783\n",
      "cross_gen Loss: 0.2671\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0765\n",
      "cross_gen Loss: 0.2659\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0755\n",
      "cross_gen Loss: 0.2652\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0750\n",
      "cross_gen Loss: 0.2648\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0749\n",
      "cross_gen Loss: 0.2646\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0749\n",
      "cross_gen Loss: 0.2645\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0131\n",
      "val Loss: 0.4990\n",
      "cross_gen Loss: 0.0792\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0035\n",
      "val Loss: 0.4731\n",
      "cross_gen Loss: 0.1133\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.4568\n",
      "cross_gen Loss: 0.1289\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.4480\n",
      "cross_gen Loss: 0.1373\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.4430\n",
      "cross_gen Loss: 0.1422\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.4398\n",
      "cross_gen Loss: 0.1454\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.4377\n",
      "cross_gen Loss: 0.1476\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.4362\n",
      "cross_gen Loss: 0.1491\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.4352\n",
      "cross_gen Loss: 0.1503\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.4345\n",
      "cross_gen Loss: 0.1512\n",
      "\n",
      "\n",
      "Realisation 4/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0104\n",
      "val Loss: 0.1551\n",
      "cross_gen Loss: 0.2629\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0035\n",
      "val Loss: 0.1440\n",
      "cross_gen Loss: 0.2580\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.1372\n",
      "cross_gen Loss: 0.2536\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.1327\n",
      "cross_gen Loss: 0.2502\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.1296\n",
      "cross_gen Loss: 0.2479\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.1276\n",
      "cross_gen Loss: 0.2464\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.1263\n",
      "cross_gen Loss: 0.2456\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.1254\n",
      "cross_gen Loss: 0.2451\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1249\n",
      "cross_gen Loss: 0.2449\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1247\n",
      "cross_gen Loss: 0.2449\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0202\n",
      "val Loss: 0.1055\n",
      "cross_gen Loss: 0.1112\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0068\n",
      "val Loss: 0.1171\n",
      "cross_gen Loss: 0.1513\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.1325\n",
      "cross_gen Loss: 0.1690\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.1442\n",
      "cross_gen Loss: 0.1794\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.1526\n",
      "cross_gen Loss: 0.1861\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.1585\n",
      "cross_gen Loss: 0.1908\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.1627\n",
      "cross_gen Loss: 0.1943\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.1658\n",
      "cross_gen Loss: 0.1969\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.1681\n",
      "cross_gen Loss: 0.1991\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.1698\n",
      "cross_gen Loss: 0.2010\n",
      "\n",
      "\n",
      "Realisation 5/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0085\n",
      "val Loss: 0.1103\n",
      "cross_gen Loss: 0.1682\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0033\n",
      "val Loss: 0.0872\n",
      "cross_gen Loss: 0.1749\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0784\n",
      "cross_gen Loss: 0.1763\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0738\n",
      "cross_gen Loss: 0.1771\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0712\n",
      "cross_gen Loss: 0.1778\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0697\n",
      "cross_gen Loss: 0.1785\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0687\n",
      "cross_gen Loss: 0.1790\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0681\n",
      "cross_gen Loss: 0.1794\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0678\n",
      "cross_gen Loss: 0.1796\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0675\n",
      "cross_gen Loss: 0.1798\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0245\n",
      "val Loss: 0.3521\n",
      "cross_gen Loss: 0.0635\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0100\n",
      "val Loss: 0.3188\n",
      "cross_gen Loss: 0.1052\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0058\n",
      "val Loss: 0.3037\n",
      "cross_gen Loss: 0.1307\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.2928\n",
      "cross_gen Loss: 0.1484\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.2843\n",
      "cross_gen Loss: 0.1620\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.2777\n",
      "cross_gen Loss: 0.1732\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0014\n",
      "val Loss: 0.2725\n",
      "cross_gen Loss: 0.1827\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.2684\n",
      "cross_gen Loss: 0.1909\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.2652\n",
      "cross_gen Loss: 0.1981\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.2626\n",
      "cross_gen Loss: 0.2043\n",
      "\n",
      "\n",
      "Realisation 6/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0079\n",
      "val Loss: 0.1130\n",
      "cross_gen Loss: 0.2531\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0026\n",
      "val Loss: 0.1048\n",
      "cross_gen Loss: 0.2613\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.0992\n",
      "cross_gen Loss: 0.2636\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0942\n",
      "cross_gen Loss: 0.2644\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.0899\n",
      "cross_gen Loss: 0.2650\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0863\n",
      "cross_gen Loss: 0.2657\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0833\n",
      "cross_gen Loss: 0.2667\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0808\n",
      "cross_gen Loss: 0.2678\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0787\n",
      "cross_gen Loss: 0.2689\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0769\n",
      "cross_gen Loss: 0.2701\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0206\n",
      "val Loss: 0.3780\n",
      "cross_gen Loss: 0.1118\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0055\n",
      "val Loss: 0.3475\n",
      "cross_gen Loss: 0.1698\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.3443\n",
      "cross_gen Loss: 0.1947\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0015\n",
      "val Loss: 0.3450\n",
      "cross_gen Loss: 0.2072\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.3460\n",
      "cross_gen Loss: 0.2144\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.3467\n",
      "cross_gen Loss: 0.2192\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.3470\n",
      "cross_gen Loss: 0.2225\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.3469\n",
      "cross_gen Loss: 0.2250\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.3465\n",
      "cross_gen Loss: 0.2270\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.3460\n",
      "cross_gen Loss: 0.2285\n",
      "\n",
      "\n",
      "Realisation 7/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0056\n",
      "val Loss: 0.0976\n",
      "cross_gen Loss: 0.3989\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0019\n",
      "val Loss: 0.0912\n",
      "cross_gen Loss: 0.4065\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0875\n",
      "cross_gen Loss: 0.4078\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0848\n",
      "cross_gen Loss: 0.4090\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0828\n",
      "cross_gen Loss: 0.4102\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0813\n",
      "cross_gen Loss: 0.4112\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0802\n",
      "cross_gen Loss: 0.4120\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0794\n",
      "cross_gen Loss: 0.4127\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.0788\n",
      "cross_gen Loss: 0.4132\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.0783\n",
      "cross_gen Loss: 0.4135\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "val Loss: 0.4531\n",
      "cross_gen Loss: 0.1355\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0090\n",
      "val Loss: 0.3759\n",
      "cross_gen Loss: 0.2012\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0035\n",
      "val Loss: 0.3452\n",
      "cross_gen Loss: 0.2386\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.3293\n",
      "cross_gen Loss: 0.2602\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.3193\n",
      "cross_gen Loss: 0.2732\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.3121\n",
      "cross_gen Loss: 0.2813\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.3066\n",
      "cross_gen Loss: 0.2864\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.3021\n",
      "cross_gen Loss: 0.2898\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2985\n",
      "cross_gen Loss: 0.2921\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.2956\n",
      "cross_gen Loss: 0.2936\n",
      "\n",
      "\n",
      "Realisation 8/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0083\n",
      "val Loss: 0.1500\n",
      "cross_gen Loss: 0.3223\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.1240\n",
      "cross_gen Loss: 0.3196\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.1145\n",
      "cross_gen Loss: 0.3179\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.1099\n",
      "cross_gen Loss: 0.3174\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.1074\n",
      "cross_gen Loss: 0.3175\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.1060\n",
      "cross_gen Loss: 0.3181\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1051\n",
      "cross_gen Loss: 0.3187\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.1046\n",
      "cross_gen Loss: 0.3194\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1042\n",
      "cross_gen Loss: 0.3200\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0000\n",
      "val Loss: 0.1040\n",
      "cross_gen Loss: 0.3205\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0188\n",
      "val Loss: 0.7592\n",
      "cross_gen Loss: 0.1657\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0052\n",
      "val Loss: 0.6799\n",
      "cross_gen Loss: 0.2049\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0023\n",
      "val Loss: 0.6415\n",
      "cross_gen Loss: 0.2167\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.6183\n",
      "cross_gen Loss: 0.2227\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.6033\n",
      "cross_gen Loss: 0.2268\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.5931\n",
      "cross_gen Loss: 0.2300\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.5861\n",
      "cross_gen Loss: 0.2327\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.5812\n",
      "cross_gen Loss: 0.2350\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.5777\n",
      "cross_gen Loss: 0.2371\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.5752\n",
      "cross_gen Loss: 0.2389\n",
      "\n",
      "\n",
      "Realisation 9/10\n",
      "Lesson 1/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0068\n",
      "val Loss: 0.1250\n",
      "cross_gen Loss: 0.2787\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0984\n",
      "cross_gen Loss: 0.2861\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0017\n",
      "val Loss: 0.0882\n",
      "cross_gen Loss: 0.2886\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.0845\n",
      "cross_gen Loss: 0.2886\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0837\n",
      "cross_gen Loss: 0.2876\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "val Loss: 0.0840\n",
      "cross_gen Loss: 0.2862\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.0848\n",
      "cross_gen Loss: 0.2846\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.0858\n",
      "cross_gen Loss: 0.2831\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0868\n",
      "cross_gen Loss: 0.2816\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.0877\n",
      "cross_gen Loss: 0.2804\n",
      "\n",
      "\n",
      "Lesson 2/2\n",
      "Epoch 50/500\n",
      "----------\n",
      "train Loss: 0.0202\n",
      "val Loss: 0.8035\n",
      "cross_gen Loss: 0.0790\n",
      "\n",
      "\n",
      "Epoch 100/500\n",
      "----------\n",
      "train Loss: 0.0063\n",
      "val Loss: 0.8018\n",
      "cross_gen Loss: 0.1181\n",
      "\n",
      "\n",
      "Epoch 150/500\n",
      "----------\n",
      "train Loss: 0.0031\n",
      "val Loss: 0.7871\n",
      "cross_gen Loss: 0.1355\n",
      "\n",
      "\n",
      "Epoch 200/500\n",
      "----------\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.7726\n",
      "cross_gen Loss: 0.1451\n",
      "\n",
      "\n",
      "Epoch 250/500\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "val Loss: 0.7612\n",
      "cross_gen Loss: 0.1514\n",
      "\n",
      "\n",
      "Epoch 300/500\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "val Loss: 0.7528\n",
      "cross_gen Loss: 0.1558\n",
      "\n",
      "\n",
      "Epoch 350/500\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "val Loss: 0.7467\n",
      "cross_gen Loss: 0.1591\n",
      "\n",
      "\n",
      "Epoch 400/500\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "val Loss: 0.7422\n",
      "cross_gen Loss: 0.1617\n",
      "\n",
      "\n",
      "Epoch 450/500\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "val Loss: 0.7389\n",
      "cross_gen Loss: 0.1637\n",
      "\n",
      "\n",
      "Epoch 500/500\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 0.7365\n",
      "cross_gen Loss: 0.1653\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-e3521816a5bf>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[1;31m# averaging over teacher realisations\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[0merrors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mn_runs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 33\u001B[1;33m \u001B[0mplot_history\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\catastrophicForgetting\\research\\main.py\u001B[0m in \u001B[0;36mplot_history\u001B[1;34m(errors)\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxlabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Epoch\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mylabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Mean Squared Error\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"(MSE averaged over {} realisations)\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_runs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     93\u001B[0m     \u001B[1;31m# plt.gca().set_ylim(0, 1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'n_runs' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creates a pair of Teachers (T1, T2),\n",
    "each teacher generates:\n",
    " -P examples of N-parameter random vectors X generated from normal distribution\n",
    "with variance sgm_w**2\n",
    " -P examples of linear signal Y created from random vectors.\n",
    " A simple white noise with variance sgm_e**2 is added to the signals.\n",
    "\n",
    "Generated data is splitted with 2:1 ratio for training/validation purposes.\n",
    "\n",
    "Creates Student model, together with SGD optimizer with learning ratio lr and MSE loss function.\n",
    "Prepares training, validation and cross-generalization datasets with scaling of the input vectors.\n",
    "\n",
    "Runs 2 subsequent lessons runned for epochs1 and epochs2 time.\n",
    "Returns dictionary with training, validation and cross generalization errors for full simulation\n",
    "\"\"\"\n",
    "\n",
    "n_runs=10\n",
    "realisations=[]\n",
    "for r in range(n_runs):\n",
    "    print('Realisation {}/{}'.format(r, n_runs))\n",
    "    history=main(N1, N2,\n",
    "                 P1, P2,\n",
    "                 sgm_w1, sgm_w2,\n",
    "                 sgm_e, learning_rate,\n",
    "                 epochs1, epochs2)\n",
    "    realisations.append(history)\n",
    "c=Counter()\n",
    "for r in realisations:\n",
    "    c.update(r)\n",
    "# averaging over teacher realisations\n",
    "errors = pd.DataFrame(c)/n_runs\n",
    "plot_history(errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}